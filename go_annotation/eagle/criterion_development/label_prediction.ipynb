{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following some of the examples here: https://github.com/pytorch/fairseq/tree/master/examples/roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = RobertaModel.from_pretrained('/projects/deepgreen/pstjohn/roberta_base_checkpoint/',\n",
    "                                       checkpoint_file='checkpoint_best.pt')\n",
    "_ = roberta.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.uniprot.org/uniprot/P14618.fasta\n",
    "example_sequence = \\\n",
    "\"\"\"\n",
    "MSKPHSEAGTAFIQTQQLHAAMADTFLEHMCRLDIDSPPITARNTGIICTIGPASRSVET\n",
    "LKEMIKSGMNVARLNFSHGTHEYHAETIKNVRTATESFASDPILYRPVAVALDTKGPEIR\n",
    "TGLIKGSGTAEVELKKGATLKITLDNAYMEKCDENILWLDYKNICKVVEVGSKIYVDDGL\n",
    "ISLQVKQKGADFLVTEVENGGSLGSKKGVNLPGAAVDLPAVSEKDIQDLKFGVEQDVDMV\n",
    "FASFIRKASDVHEVRKVLGEKGKNIKIISKIENHEGVRRFDEILEASDGIMVARGDLGIE\n",
    "IPAEKVFLAQKMMIGRCNRAGKPVICATQMLESMIKKPRPTRAEGSDVANAVLDGADCIM\n",
    "LSGETAKGDYPLEAVRMQHLIAREAEAAIYHLQLFEELRRLAPITSDPTEATAVGAVEAS\n",
    "FKCCSGAIIVLTKSGRSAHQVARYRPRAPIIAVTRNPQTARQAHLYRGIFPVLCKDPVQE\n",
    "AWAEDVDLRVNFAMNVGKARGFFKKGDVVIVLTGWRPGSGFTNTMRVVPVP\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the roberta example on fairseq, we're not using the GPT-2 byte-pair encoder, so the standard `roberta.encode` and `roberta.decode` methods won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20,  8, 15, 14, 21,  8,  9,  5,  6, 11,  5, 17, 12, 16, 11, 16, 16,  4,\n",
       "        21,  5,  5, 20,  5, 13, 11, 17,  4,  9, 21, 20, 23, 10,  4, 13, 12, 13,\n",
       "         8, 14, 14, 12, 11,  5, 10, 18, 11,  6, 12, 12, 23, 11, 12,  6, 14,  5,\n",
       "         8, 10,  8,  7,  9, 11,  4, 15,  9, 20, 12, 15,  8,  6, 20, 18,  7,  5,\n",
       "        10,  4, 18, 17,  8, 21,  6, 11, 21,  9, 19, 21,  5,  9, 11, 12, 15, 18,\n",
       "         7, 10, 11,  5, 11,  9,  8, 17,  5,  8, 13, 14, 12,  4, 19, 10, 14,  7,\n",
       "         5,  7,  5,  4, 13, 11, 15,  6, 14,  9, 12, 10, 11,  6,  4, 12, 15,  6,\n",
       "         8,  6, 11,  5,  9,  7,  9,  4, 15, 15,  6,  5, 11,  4, 15, 12, 11,  4,\n",
       "        13, 18,  5, 19, 20,  9, 15, 23, 13,  9, 18, 12,  4, 22,  4, 13, 19, 15,\n",
       "        18, 12, 23, 15,  7,  7,  9,  7,  6,  8, 15, 12, 19,  7, 13, 13,  6,  4,\n",
       "        12,  8,  4, 16,  7, 15, 16, 15,  6,  5, 13, 17,  4,  7, 11,  9,  7,  9,\n",
       "        18,  6,  6,  8,  4,  6,  8, 15, 15,  6,  7, 18,  4, 14,  6,  5,  5,  7,\n",
       "        13,  4, 14,  5,  7,  8,  9, 15, 13, 12, 16, 13,  4, 15, 17,  6,  7,  9,\n",
       "        16, 13,  7, 13, 20,  7, 17,  5,  8, 17, 12, 10, 15,  5,  8, 13,  7, 21,\n",
       "         9,  7, 10, 15,  7,  4,  6,  9, 15,  6, 15, 18, 12, 15, 12, 12,  8, 15,\n",
       "        12,  9, 18, 21,  9,  6,  7, 10, 10, 17, 13,  9, 12,  4,  9,  5,  8, 13,\n",
       "         6, 12, 20,  7,  5, 10,  6, 13,  4,  6, 12,  9, 12, 14,  5,  9, 15,  7,\n",
       "        17,  4,  5, 16, 15, 20, 20, 12,  6, 10, 23, 18, 10,  5,  6, 15, 14,  7,\n",
       "        12, 23,  5, 11, 16, 20,  4,  9,  8, 20, 12, 15, 15, 14, 10, 14, 11, 10,\n",
       "         5,  9,  6,  8, 13,  7,  5, 18,  5,  7,  4, 13,  6,  5, 13, 23, 12, 20,\n",
       "         4,  8,  6,  9, 11,  5, 15,  6, 13, 19, 14,  4,  9,  5,  7, 10, 20, 16,\n",
       "        21,  4, 12,  5, 10,  9,  5,  9,  5,  5, 12, 19, 21,  4, 16,  4, 17,  9,\n",
       "         9,  4, 10, 10,  4,  5, 14, 12, 11,  8, 13, 14, 11,  9,  5, 11,  5,  7,\n",
       "         6,  5,  7,  9,  5,  8, 17, 15, 23, 23,  8,  6,  5, 12, 12,  7,  4, 11,\n",
       "        15,  8,  6, 10,  8,  5, 21, 16,  7,  5, 10, 19, 10, 14, 10,  5, 14, 12,\n",
       "        12,  5,  7, 11, 10, 18, 14, 16, 11,  5, 10, 16,  5, 21,  4, 19, 10,  6,\n",
       "        12, 17, 14,  7,  4, 23, 15, 13, 14,  7, 16,  9,  5, 22,  5,  9, 13,  7,\n",
       "        13,  4, 10,  7, 18, 17,  5, 20, 18,  7,  6, 15,  5, 10,  6, 17, 17, 15,\n",
       "        15,  6, 13,  7,  7, 12,  7,  4, 11,  6, 22, 10, 14,  6,  8,  6, 17, 11,\n",
       "        18, 11, 20, 10,  7,  7, 14,  7, 14,  2], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(sequence):\n",
    "    input_sequence = ' '.join(sequence.replace('\\n', ''))\n",
    "    return roberta.task.source_dictionary.encode_line(input_sequence)\n",
    "\n",
    "tokens = encode(example_sequence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU\")\n",
    "    roberta.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = roberta.extract_features(tokens.to(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the ontology object and backpropogate GO labels\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/pstjohn/Research/20201119_fairseq/go_annotation')\n",
    "\n",
    "from ontology import Ontology\n",
    "ont = Ontology()\n",
    "ont.total_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(list(ont.iter_ancestor_array()))\n",
    "index_tensor = torch.tensor(coo_matrix((arr[:, 0] + 1, (arr[:, 1], arr[:, 2]))).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32012, 88])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta.model.register_classification_head(\n",
    "    'go_prediction',\n",
    "    num_classes=ont.total_nodes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokens.to(torch.int64).unsqueeze_(0).expand((2, 532))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits, _ = roberta.model(\n",
    "        inputs,\n",
    "        features_only=True,\n",
    "        classification_head_name='go_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctionsClass.min>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_logits, _ = torch.min(torch.gather(torch.nn.functional.pad(logits, (1, 0), value=float('inf')).unsqueeze(-1).expand(-1, -1, 88), 1, index_tensor.unsqueeze(0).expand((2, -1, -1))), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1956, -0.1956, -0.0722,  ..., -0.1196, -0.0788, -0.0881],\n",
       "        [-0.1956, -0.1956, -0.0722,  ..., -0.1196, -0.0788, -0.0881]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_logits = scatter(torch.gather(logits, 1, term_tensor), ancestor_tensor, reduce='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_nodes = ont.get_head_node_indices()\n",
    "_bf_index = ont.terms_to_indices(ont.get_descendants(ont.term_index[head_nodes[0]]))\n",
    "_mp_index = ont.terms_to_indices(ont.get_descendants(ont.term_index[head_nodes[1]]))\n",
    "_cc_index = ont.terms_to_indices(ont.get_descendants(ont.term_index[head_nodes[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.gather(normed_logits, -1, convert_and_resize(_cc_index)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
