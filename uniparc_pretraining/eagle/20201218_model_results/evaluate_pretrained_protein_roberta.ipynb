{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following some of the examples here: https://github.com/pytorch/fairseq/tree/master/examples/roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = RobertaModel.from_pretrained('/projects/deepgreen/pstjohn/roberta_base_checkpoint/',\n",
    "                                       checkpoint_file='checkpoint_best.pt')\n",
    "_ = roberta.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.uniprot.org/uniprot/P14618.fasta\n",
    "example_sequence = \\\n",
    "\"\"\"\n",
    "MSKPHSEAGTAFIQTQQLHAAMADTFLEHMCRLDIDSPPITARNTGIICTIGPASRSVET\n",
    "LKEMIKSGMNVARLNFSHGTHEYHAETIKNVRTATESFASDPILYRPVAVALDTKGPEIR\n",
    "TGLIKGSGTAEVELKKGATLKITLDNAYMEKCDENILWLDYKNICKVVEVGSKIYVDDGL\n",
    "ISLQVKQKGADFLVTEVENGGSLGSKKGVNLPGAAVDLPAVSEKDIQDLKFGVEQDVDMV\n",
    "FASFIRKASDVHEVRKVLGEKGKNIKIISKIENHEGVRRFDEILEASDGIMVARGDLGIE\n",
    "IPAEKVFLAQKMMIGRCNRAGKPVICATQMLESMIKKPRPTRAEGSDVANAVLDGADCIM\n",
    "LSGETAKGDYPLEAVRMQHLIAREAEAAIYHLQLFEELRRLAPITSDPTEATAVGAVEAS\n",
    "FKCCSGAIIVLTKSGRSAHQVARYRPRAPIIAVTRNPQTARQAHLYRGIFPVLCKDPVQE\n",
    "AWAEDVDLRVNFAMNVGKARGFFKKGDVVIVLTGWRPGSGFTNTMRVVPVP\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the roberta example on fairseq, we're not using the GPT-2 byte-pair encoder, so the standard `roberta.encode` and `roberta.decode` methods won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sequence):\n",
    "    input_sequence = ' '.join(sequence.replace('\\n', ''))\n",
    "    return roberta.task.source_dictionary.encode_line(input_sequence)\n",
    "\n",
    "def decode(tokens):\n",
    "    return roberta.task.source_dictionary.string(tokens).replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20,  8, 15, 14, 21,  8,  9,  5,  6, 11,  5, 17, 12, 16, 11, 16, 16,  4,\n",
       "        21,  5,  5, 20,  5, 13, 11, 17,  4,  9, 21, 20, 23, 10,  4, 13, 12, 13,\n",
       "         8, 14, 14, 12, 11,  5, 10, 18, 11,  6, 12, 12, 23, 11, 12,  6, 14,  5,\n",
       "         8, 10,  8,  7,  9, 11,  4, 15,  9, 20, 12, 15,  8,  6, 20, 18,  7,  5,\n",
       "        10,  4, 18, 17,  8, 21,  6, 11, 21,  9, 19, 21,  5,  9, 11, 12, 15, 18,\n",
       "         7, 10, 11,  5, 11,  9,  8, 17,  5,  8, 13, 14, 12,  4, 19, 10, 14,  7,\n",
       "         5,  7,  5,  4, 13, 11, 15,  6, 14,  9, 12, 10, 11,  6,  4, 12, 15,  6,\n",
       "         8,  6, 11,  5,  9,  7,  9,  4, 15, 15,  6,  5, 11,  4, 15, 12, 11,  4,\n",
       "        13, 18,  5, 19, 20,  9, 15, 23, 13,  9, 18, 12,  4, 22,  4, 13, 19, 15,\n",
       "        18, 12, 23, 15,  7,  7,  9,  7,  6,  8, 15, 12, 19,  7, 13, 13,  6,  4,\n",
       "        12,  8,  4, 16,  7, 15, 16, 15,  6,  5, 13, 17,  4,  7, 11,  9,  7,  9,\n",
       "        18,  6,  6,  8,  4,  6,  8, 15, 15,  6,  7, 18,  4, 14,  6,  5,  5,  7,\n",
       "        13,  4, 14,  5,  7,  8,  9, 15, 13, 12, 16, 13,  4, 15, 17,  6,  7,  9,\n",
       "        16, 13,  7, 13, 20,  7, 17,  5,  8, 17, 12, 10, 15,  5,  8, 13,  7, 21,\n",
       "         9,  7, 10, 15,  7,  4,  6,  9, 15,  6, 15, 18, 12, 15, 12, 12,  8, 15,\n",
       "        12,  9, 18, 21,  9,  6,  7, 10, 10, 17, 13,  9, 12,  4,  9,  5,  8, 13,\n",
       "         6, 12, 20,  7,  5, 10,  6, 13,  4,  6, 12,  9, 12, 14,  5,  9, 15,  7,\n",
       "        17,  4,  5, 16, 15, 20, 20, 12,  6, 10, 23, 18, 10,  5,  6, 15, 14,  7,\n",
       "        12, 23,  5, 11, 16, 20,  4,  9,  8, 20, 12, 15, 15, 14, 10, 14, 11, 10,\n",
       "         5,  9,  6,  8, 13,  7,  5, 18,  5,  7,  4, 13,  6,  5, 13, 23, 12, 20,\n",
       "         4,  8,  6,  9, 11,  5, 15,  6, 13, 19, 14,  4,  9,  5,  7, 10, 20, 16,\n",
       "        21,  4, 12,  5, 10,  9,  5,  9,  5,  5, 12, 19, 21,  4, 16,  4, 17,  9,\n",
       "         9,  4, 10, 10,  4,  5, 14, 12, 11,  8, 13, 14, 11,  9,  5, 11,  5,  7,\n",
       "         6,  5,  7,  9,  5,  8, 17, 15, 23, 23,  8,  6,  5, 12, 12,  7,  4, 11,\n",
       "        15,  8,  6, 10,  8,  5, 21, 16,  7,  5, 10, 19, 10, 14, 10,  5, 14, 12,\n",
       "        12,  5,  7, 11, 10, 18, 14, 16, 11,  5, 10, 16,  5, 21,  4, 19, 10,  6,\n",
       "        12, 17, 14,  7,  4, 23, 15, 13, 14,  7, 16,  9,  5, 22,  5,  9, 13,  7,\n",
       "        13,  4, 10,  7, 18, 17,  5, 20, 18,  7,  6, 15,  5, 10,  6, 17, 17, 15,\n",
       "        15,  6, 13,  7,  7, 12,  7,  4, 11,  6, 22, 10, 14,  6,  8,  6, 17, 11,\n",
       "        18, 11, 20, 10,  7,  7, 14,  7, 14,  2], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = encode(example_sequence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSKPHSEAGTAFIQTQQLHAAMADTFLEHMCRLDIDSPPITARNTGIICTIGPASRSVET\n",
      "LKEMIKSGMNVARLNFSHGTHEYHAETIKNVRTATESFASDPILYRPVAVALDTKGPEIR\n",
      "TGLIKGSGTAEVELKKGATLKITLDNAYMEKCDENILWLDYKNICKVVEVGSKIYVDDGL\n",
      "ISLQVKQKGADFLVTEVENGGSLGSKKGVNLPGAAVDLPAVSEKDIQDLKFGVEQDVDMV\n",
      "FASFIRKASDVHEVRKVLGEKGKNIKIISKIENHEGVRRFDEILEASDGIMVARGDLGIE\n",
      "IPAEKVFLAQKMMIGRCNRAGKPVICATQMLESMIKKPRPTRAEGSDVANAVLDGADCIM\n",
      "LSGETAKGDYPLEAVRMQHLIAREAEAAIYHLQLFEELRRLAPITSDPTEATAVGAVEAS\n",
      "FKCCSGAIIVLTKSGRSAHQVARYRPRAPIIAVTRNPQTARQAHLYRGIFPVLCKDPVQE\n",
      "AWAEDVDLRVNFAMNVGKARGFFKKGDVVIVLTGWRPGSGFTNTMRVVPVP\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "decoded_sequence = '\\n'.join(wrap(decode(tokens), width=60))\n",
    "print(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence == example_sequence[1:-1]  # stripping leading and tailing newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU\")\n",
    "    roberta.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = roberta.extract_features(tokens.to(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1737,  0.0976, -0.0376,  ...,  0.0724, -0.0361,  0.0857],\n",
       "         [-0.1052,  0.2354, -0.1681,  ..., -0.0185,  0.1915, -0.1655],\n",
       "         [-0.0129,  0.0157, -0.1035,  ..., -0.0133,  0.1601, -0.0342],\n",
       "         ...,\n",
       "         [ 0.0780,  0.2138, -0.0877,  ..., -0.0448,  0.2261,  0.1889],\n",
       "         [ 0.1001,  0.2172,  0.1093,  ...,  0.0376, -0.0170, -0.0922],\n",
       "         [ 0.1199,  0.2842,  0.0715,  ...,  0.0889, -0.0753,  0.1925]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
